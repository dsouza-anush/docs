---
title: "Managed Inference and Agents API /v1/embeddings"
description: "The /v1/embeddings endpoint generates vector embeddings (basically, a list of numbers) for a provided set of input texts. These embeddings are optimiz..."
---

## Table of Contents [expand]

        - [Request Body Parameters](#request-body-parameters)

        - [Request Headers](#request-headers)

        - [Response Format](#response-format)

        - [Example Request](#example-request)

        - [Example Response](#example-response)

The `/v1/embeddings` endpoint generates vector embeddings (basically, a list of numbers) for a provided set of input texts. These embeddings are optimized for various use cases, such as search, classification, and clustering. You can customize how inputs are processed and choose different embedding types to suit your needs.

## Request Body Parameters

### Required Parameters

| model 
| string 
| ID of the embedding model to use 
| `"cohere-embed-multilingual"` 

| input 
| array 
| single string or an array of strings for the model to embedmax of: `96` strings, `2048` characters eachrecommended: length less than `512` tokens per string 
| `["example string 1", "example string 2"]` 

### Optional Parameters

| input_type 
| enum 
| specifies the type of input passed to the model (prepends special tokens to the input)one of:`search_document`, `search_query`, `classification`, `clustering` 
| `"search_document"` 
| `"search_query"` 

| encoding_format 
| enum 
| determines the encoding format of the outputone of: `raw` or `base64` 
| `"raw"` 
| `"base64"` 

| embedding_type 
| enum 
| specifies the type(s) of embeddings to return (`float`, `int8`, `uint8`, `binary`, `ubinary`) 
| `"float"` 
| `"int8"` 

| allow_ignored_params 
| boolean 
| ignore unsupported parameters in request instead of throwing an error 
| `false` 
| `true` 

## Request Headers

In the following example, we assume your model resource has an alias of `"EMBEDDING"` (meaning you created the model resource with an `--as EMBEDDING` flag).

| `Authorization` 
| string 
| your AI add-on’s ‘EMBEDDING_KEY’ value (API bearer token) 

Inference `curl` requests must include an `Authorization` header containing your Heroku Inference key for the specified model.

## Response Format

When a request is successful, the API returns a JSON object with the following structure:

| object 
| string 
| outer structure of the responsealways: `"list"` 

| data 
| array of objects 
| list of [embeddings](#embedding-object) generated, one per input 

| model 
| string 
| ID of the model that generated the embeddings 

| usage 
| object 
| metadata about token usage (`prompt_tokens`, `total_tokens`) 

### Embedding Object

Each object inside the `data` array includes:

| object 
| string 
| type of objectalways: `"embedding"` 

| index 
| integer 
| index of the input string this embedding corresponds to (starting from 0) 

| embedding 
| array or string 
| embedding vector (of type `embedding_type`) 

## Example Request

Let’s walk through an example `/v1/embeddings` `curl` request.

First, use this command to set your Heroku environment variables as local variables.

```bash
eval $(heroku config -a $APP_NAME --shell | grep '^EMBEDDING_' | sed 's/^/export /' | tee >(cat >&2))
```

Next, send the `curl` request:

```bash
curl $EMBEDDING_URL/v1/embeddings \
 -H "Authorization: Bearer $EMBEDDING_KEY" \
 -d @-
