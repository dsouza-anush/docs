---
title: "AI Studio"
description: "Visual interface for testing AI models, tuning prompts, and experimenting with tools before deploying to production"
---

Heroku AI Studio is a web-based playground that enables developers to explore, test, and refine AI capabilities before integrating them into applications. It provides an interactive environment to experiment with models, prompts, parameters, and tools without writing code.

## Key Features

- **Interactive Chat Interface** - Test conversational AI with real-time responses
- **Parameter Tuning** - Adjust temperature, max tokens, and other model parameters
- **Agent Mode** - Test tool execution with Heroku and MCP tools
- **Code Export** - Copy validated configurations as code snippets
- **Multi-Model Support** - Switch between different AI models instantly
- **Dark/Light Mode** - Customize the interface to your preference

## Use Cases

### Prompt Engineering

Fine-tune prompts for your specific use case without deploying code:

- **Customer Support Chatbots** - Test different system prompts to ensure appropriate tone and helpfulness
- **Content Generation** - Experiment with creative vs. factual writing styles
- **Data Extraction** - Validate prompt structures for parsing structured data from text
- **Translation Tasks** - Compare output quality across different prompt formulations

**Example Workflow:**
1. Start with a basic prompt in AI Studio
2. Adjust system instructions to guide behavior
3. Test with various user inputs
4. Refine based on output quality
5. Export finalized prompt to your code

### Model Exploration

Understand the capabilities and limitations of different models:

- **Compare Response Quality** - Test the same prompt across Claude 4 Sonnet, Haiku, and other models
- **Assess Speed vs. Quality** - Evaluate which model balances performance with your requirements
- **Test Extended Thinking** - Experiment with extended thinking for complex reasoning tasks
- **Evaluate Cost Trade-offs** - Understand token usage across different models

### Tool Testing

Verify that tools work correctly before production deployment:

- **Database Queries** - Test pg_psql queries against your follower database
- **Code Execution** - Validate Ruby, Python, Go, or Node code execution tools
- **Custom MCP Tools** - Ensure your deployed MCP servers respond correctly
- **Multi-Tool Workflows** - Test agents that use multiple tools in sequence

**Example: Database Query Testing**
1. Enable Agent Mode in AI Studio
2. Add pg_psql tool
3. Ask "Show me all users created in the last 7 days"
4. Verify the agent constructs the correct SQL query
5. Check the returned results match expectations

### Integration Preparation

Prepare for production integration with validated configurations:

- **System Prompt Validation** - Ensure instructions are clear and effective
- **Parameter Optimization** - Find the right temperature and token limits
- **Error Handling** - Test edge cases and error scenarios
- **Code Generation** - Export working configurations as code snippets

## Get Started with AI Studio

To access AI Studio:

- Open the [Heroku Dashboard](https://dashboard.heroku.com/).

- Select the app that has the Managed Inference and Agents add-on attached.

- Select the `Resources` tab.

- Select `Heroku Managed Inference and Agents` under `Add-on Services`. If you donâ€™t have the add-on yet, use the search bar to find and add the Heroku Managed Inference and Agents add-on.

- Select `Open Playground`.

## Using AI Studio

### Chat Interface

The main chat interface allows you to:

- **Send Messages** - Type questions or instructions to test model responses
- **View Responses** - See real-time answers with streaming support
- **Review History** - Scroll through the conversation to track context
- **Start New Conversations** - Clear history to begin fresh tests

### Configure Parameters

Adjust AI behavior by modifying parameters in the right panel:

#### System Prompt
Instructions that guide the model's behavior, tone, and expertise.

**Examples:**
- "You are a helpful customer support agent. Be friendly and concise."
- "You are a data analyst. Provide technical, data-driven responses."
- "You are a creative writer. Use vivid descriptions and storytelling."

#### Temperature (0.0 - 1.0)
Controls response randomness and creativity.

- **0.0 - 0.3**: Focused and deterministic (good for factual responses)
- **0.4 - 0.7**: Balanced creativity and consistency
- **0.8 - 1.0**: More creative and diverse outputs

#### Top-p (0.0 - 1.0)
Nucleus sampling that limits token selection to most probable options.

- Lower values (0.5-0.7): More focused responses
- Higher values (0.9-0.999): More diverse vocabulary

#### Max Tokens
Maximum response length in tokens (approximately 4 characters per token).

- **512**: Short, concise responses
- **1024**: Standard responses
- **4096+**: Long-form content

#### Stop Sequences
Text patterns that immediately stop generation when encountered.

**Example:** Add `---` as a stop sequence to prevent the model from generating beyond that marker.

### Agent Mode

Enable Agent Mode to allow the model to use tools:

1. Toggle **Agent Mode** on in the interface
2. Click **Tools** in the upper-right corner
3. Select which tools to enable:
   - Heroku built-in tools (code execution, database queries)
   - Your custom MCP tools
4. Configure tool-specific parameters like `target_app_name`
5. Start chatting - the agent will automatically call tools when needed

**Example Agent Interaction:**

```
User: "How many users signed up yesterday?"

Agent: I'll query the database to find that information.
[Agent calls pg_psql tool]

Agent: Based on the query results, 47 users signed up yesterday.
```

### Export Code

Once you've validated a configuration:

1. Click **View Code** in the interface
2. Choose your preferred language (Python, JavaScript, cURL, etc.)
3. Copy the generated code snippet
4. Paste into your application

The exported code includes:
- Your validated system prompt
- All parameter settings
- Tool configurations
- Authentication setup

### Interface Controls

- **Moon/Sun Icon** - Switch between dark and light modes
- **Tools Button** - Configure agent tools
- **Parameters Panel** - Adjust model settings
- **New Chat** - Start a fresh conversation
- **Model Selector** - Switch between available models

## Best Practices

### Start Simple, Then Iterate
- Begin with basic prompts and parameters
- Test with a few examples
- Gradually add complexity as you understand model behavior

### Use Agent Mode Strategically
- Test tools individually before combining them
- Verify tool responses match expectations
- Set appropriate `max_calls` to prevent infinite loops

### Document Your Findings
- Note which prompts work best for your use case
- Record optimal parameter settings
- Save successful configurations via code export

### Test Edge Cases
- Try unusual inputs to understand model limitations
- Test error handling scenarios
- Verify behavior with empty or malformed inputs

## Troubleshooting

### Tool Not Responding
- Verify your target app has the necessary resources (database, dynos)
- Check that follower databases are properly configured
- Ensure MCP servers are deployed and registered

### Unexpected Responses
- Review system prompt for clarity and specificity
- Adjust temperature if responses are too random or too rigid
- Consider adding stop sequences to prevent over-generation

### Slow Performance
- Try a faster model like Claude 3.5 Haiku
- Reduce max_tokens for quicker responses
- Check if tool execution is causing delays

## Related Resources

<CardGroup cols={2}>
  <Card title="Chat Completions API" href="/inference-api/chat-completions" icon="comments">
    Integrate validated prompts into your code
  </Card>
  <Card title="Agents API" href="/inference-api/agents-heroku" icon="robot">
    Deploy agent workflows to production
  </Card>
  <Card title="Heroku Tools" href="/tool-use/heroku-tools" icon="wrench">
    Learn about available tools
  </Card>
  <Card title="Model Cards" href="https://devcenter.heroku.com/articles/heroku-inference-api-model-cards" icon="book">
    Compare model capabilities
  </Card>
</CardGroup>
