---
title: "Prompt patterns & evaluations"
description: "Improve chat completion quality on Heroku AI with prompt templates and lightweight evaluation loops."
fullWidth: true
---

<section style={{ margin: '0 calc(-1 * min(8vw, 96px)) 3rem', padding: '0 min(8vw, 96px)' }}>
  <p>
    This guide distills prompt optimization practices from the OpenAI Cookbook so you can harden chat-based Heroku AI apps without relying on the Agents API. Adapted references: <a href="https://cookbook.openai.com/examples/optimize_prompts" target="_blank" rel="noopener noreferrer">Optimize Prompts</a> and <a href="https://cookbook.openai.com/examples/evaluation/building_resilient_prompts_using_an_evaluation_flywheel" target="_blank" rel="noopener noreferrer">Evaluation Flywheel</a>.
  </p>
</section>

## Structure prompts for reuse

<section style={{ margin: '0 calc(-1 * min(8vw, 96px)) 2rem', padding: '0 min(8vw, 96px)' }}>
  <div style={{
    padding: '2rem',
    borderRadius: '16px',
    background: 'linear-gradient(135deg, #ffb3d9 0%, #ffcba4 50%, #fff5d6 100%)',
    border: '1px solid rgba(255,255,255,0.2)',
    color: '#ffffff',
    marginBottom: '2rem',
    boxShadow: '0 8px 16px rgba(0, 0, 0, 0.1)',
    textShadow: '0 1px 2px rgba(0, 0, 0, 0.1)'
  }}>
    <h3 style={{ marginTop: 0, color: '#ffffff', fontWeight: '700' }}>Template anatomy</h3>
    <ul style={{ color: '#ffffff', lineHeight: '1.7' }}>
      <li><strong>System message</strong>: role, tone, forbidden behaviors.</li>
      <li><strong>Instructions block</strong>: numbered steps to follow (use bullet formatting from the cookbook).</li>
      <li><strong>Reference data</strong>: optional context, clearly delimited.</li>
      <li><strong>Output contract</strong>: JSON schema or textual requirements to aid parsing.</li>
    </ul>
    <p style={{ marginBottom: 0, color: '#ffffff' }}>
      Keep variants in source control so changes can be reviewed just like code.
    </p>
  </div>
</section>

<section style={{ margin: '0 calc(-1 * min(8vw, 96px)) 3rem', padding: '0 min(8vw, 96px)' }}>

```python
PROMPT = {
    "role": "system",
    "content": (
        "You are a Heroku AI support assistant.\n"
        "# Style\n"
        "- Be concise.\n"
        "- Cite docs pages when helpful.\n"
        "# Disallowed\n"
        "- Never invent plan names or pricing.\n"
        "# Output\n"
        "Respond in Markdown with a short list of actions."
    ),
}
```

<Note>
Store prompts alongside unit tests so changes must pass automated checks before deployment.
</Note>

</section>

## Automated prompt reviews

<section style={{ margin: '0 calc(-1 * min(8vw, 96px)) 2rem', padding: '0 min(8vw, 96px)' }}>
  <div style={{
    padding: '2rem',
    borderRadius: '16px',
    background: 'linear-gradient(135deg, #f5a3d7 0%, #ffc4e8 50%, #ffe5f5 100%)',
    border: '1px solid rgba(255,255,255,0.2)',
    color: '#ffffff',
    marginBottom: '2rem',
    boxShadow: '0 8px 16px rgba(0, 0, 0, 0.1)',
    textShadow: '0 1px 2px rgba(0, 0, 0, 0.1)'
  }}>
    <h3 style={{ marginTop: 0, color: '#ffffff', fontWeight: '700' }}>Checker workflow</h3>
    <ol style={{ color: '#ffffff', lineHeight: '1.7' }}>
      <li>Run prompt text through heuristic checkers (linting length, missing sections).</li>
      <li>Optionally call the chat completions API with a "critic" system message to flag contradictions or formatting gaps (inspired by the cookbook's multi-agent loop).</li>
      <li>Return actionable feedback for human review.</li>
    </ol>
    <p style={{ marginBottom: 0, color: '#ffffff' }}>
      Keep the critic prompt deterministic (low temperature) and limit output to a structured checklist.
    </p>
  </div>
</section>

<section style={{ margin: '0 calc(-1 * min(8vw, 96px)) 3rem', padding: '0 min(8vw, 96px)' }}>

```python
def audit_prompt(candidate: str) -> str:
    critic = client.chat.completions.create(
        model="claude-3-5-haiku",
        messages=[
            {
                "role": "system",
                "content": (
                    "You are PromptChecker.\n"
                    "Identify contradictions, missing output rules, or unclear tone.\n"
                    "Respond as JSON with keys: has_issue (bool), notes (array of strings)."
                ),
            },
            {"role": "user", "content": candidate},
        ],
        temperature=0.0,
        max_tokens=500,
    )
    return critic.choices[0].message.content
```

<Note>
Haiku keeps costs low for CI pipelines; switch to Sonnet for more nuanced critiques.
</Note>

</section>

## Evaluation flywheel

<section style={{ margin: '0 calc(-1 * min(8vw, 96px)) 2rem', padding: '0 min(8vw, 96px)' }}>
  <div style={{
    padding: '2rem',
    borderRadius: '16px',
    background: 'linear-gradient(135deg, #d4e4ff 0%, #b8d0ff 50%, #9fc5ff 100%)',
    border: '1px solid rgba(255,255,255,0.2)',
    color: '#ffffff',
    marginBottom: '2rem',
    boxShadow: '0 8px 16px rgba(0, 0, 0, 0.1)',
    textShadow: '0 1px 2px rgba(0, 0, 0, 0.1)'
  }}>
    <h3 style={{ marginTop: 0, color: '#ffffff', fontWeight: '700' }}>Cycle overview</h3>
    <ol style={{ color: '#ffffff', lineHeight: '1.7' }}>
      <li><strong>Collect</strong> failing traces from production and label failure modes.</li>
      <li><strong>Measure</strong> with LLM graders scoring binary pass/fail outcomes.</li>
      <li><strong>Improve</strong> prompts or context, re-run graders, and deploy if scores rise.</li>
    </ol>
    <p style={{ marginBottom: 0, color: '#ffffff' }}>
      Align graders with human expectations using the cookbook's TPR/TNR approach.
    </p>
  </div>
</section>

<section style={{ margin: '0 calc(-1 * min(8vw, 96px)) 3rem', padding: '0 min(8vw, 96px)' }}>

```python
def run_eval(example: dict) -> bool:
    response = client.chat.completions.create(
        model="claude-3-5-sonnet",
        messages=[
            {"role": "system", "content": "Judge if the assistant followed policy. Reply PASS or FAIL."},
            {"role": "user", "content": example["transcript"]},
        ],
        temperature=0.0,
        max_tokens=10,
    )
    verdict = response.choices[0].message.content.strip().upper()
    return verdict == "PASS"
```

<Note>
Run graders inside Heroku Scheduler or CI; persist scores to Postgres so you can chart quality over time.
</Note>

</section>
